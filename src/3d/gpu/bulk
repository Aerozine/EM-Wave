// Device macros for accessing 2D arrays with column-major indexing
#define GET_D(data, nx, i, j) ((data)[(nx) * (j) + (i)])
#define SET_D(data, nx, i, j, val) ((data)[(nx) * (j) + (i)] = (val))

// CUDA kernel for updating hx
__global__ void update_hx_kernel(double *hx, const double *ez, 
                                  int nx, int ny, double chy) {
  int i = blockIdx.x * blockDim.x + threadIdx.x;
  int j = blockIdx.y * blockDim.y + threadIdx.y;
  
  if (i < nx && j < ny - 1) {
    double hx_ij = GET_D(hx, nx, i, j) - 
                   chy * (GET_D(ez, nx, i, j + 1) - GET_D(ez, nx, i, j));
    SET_D(hx, nx, i, j, hx_ij);
  }
}

// CUDA kernel for updating hy
__global__ void update_hy_kernel(double *hy, const double *ez,
                                  int nx, int ny, double chx) {
  int i = blockIdx.x * blockDim.x + threadIdx.x;
  int j = blockIdx.y * blockDim.y + threadIdx.y;
  
  if (i < nx - 1 && j < ny) {
    double hy_ij = GET_D(hy, nx - 1, i, j) + 
                   chx * (GET_D(ez, nx, i + 1, j) - GET_D(ez, nx, i, j));
    SET_D(hy, nx - 1, i, j, hy_ij);
  }
}

// CUDA kernel for updating ez
__global__ void update_ez_kernel(double *ez, const double *hx, const double *hy,
                                  int nx, int ny, double cex, double cey) {
  int i = blockIdx.x * blockDim.x + threadIdx.x;
  int j = blockIdx.y * blockDim.y + threadIdx.y;
  
  if (i > 0 && i < nx - 1 && j > 0 && j < ny - 1) {
    double ez_ij = GET_D(ez, nx, i, j) +
                   cex * (GET_D(hy, nx - 1, i, j) - GET_D(hy, nx - 1, i - 1, j)) -
                   cey * (GET_D(hx, nx, i, j) - GET_D(hx, nx, i, j - 1));
    SET_D(ez, nx, i, j, ez_ij);
  }
}

// GPU data structure
struct gpu_data {
  double *d_ez;
  double *d_hx;
  double *d_hy;
  int nx_ez, ny_ez;
  int nx_hx, ny_hx;
  int nx_hy, ny_hy;
};

// Initialize GPU data
int init_gpu_data(struct gpu_data *gpu, struct data *ez, 
                  struct data *hx, struct data *hy) {
  gpu->nx_ez = ez->nx;
  gpu->ny_ez = ez->ny;
  gpu->nx_hx = hx->nx;
  gpu->ny_hx = hx->ny;
  gpu->nx_hy = hy->nx;
  gpu->ny_hy = hy->ny;
  
  size_t size_ez = ez->nx * ez->ny * sizeof(double);
  size_t size_hx = hx->nx * hx->ny * sizeof(double);
  size_t size_hy = hy->nx * hy->ny * sizeof(double);
  
  cudaError_t err;
  
  err = cudaMalloc(&gpu->d_ez, size_ez);
  if (err != cudaSuccess) {
    printf("CUDA Error allocating ez: %s\n", cudaGetErrorString(err));
    return 1;
  }
  
  err = cudaMalloc(&gpu->d_hx, size_hx);
  if (err != cudaSuccess) {
    printf("CUDA Error allocating hx: %s\n", cudaGetErrorString(err));
    cudaFree(gpu->d_ez);
    return 1;
  }
  
  err = cudaMalloc(&gpu->d_hy, size_hy);
  if (err != cudaSuccess) {
    printf("CUDA Error allocating hy: %s\n", cudaGetErrorString(err));
    cudaFree(gpu->d_ez);
    cudaFree(gpu->d_hx);
    return 1;
  }
  
  // Copy initial data to GPU
  cudaMemcpy(gpu->d_ez, ez->values, size_ez, cudaMemcpyHostToDevice);
  cudaMemcpy(gpu->d_hx, hx->values, size_hx, cudaMemcpyHostToDevice);
  cudaMemcpy(gpu->d_hy, hy->values, size_hy, cudaMemcpyHostToDevice);
  
  return 0;
}

// Free GPU data
void free_gpu_data(struct gpu_data *gpu) {
  if (gpu->d_ez) cudaFree(gpu->d_ez);
  if (gpu->d_hx) cudaFree(gpu->d_hx);
  if (gpu->d_hy) cudaFree(gpu->d_hy);
}

// Main CUDA-optimized solve function
int solve_cuda(struct SimulationParams *sim_params,
               struct PhysicalParams *phys_params, int problem_id) {
  DEBUG_PRINT("Starting CUDA computation on process %d, with :\n\tnx from %d to "
              "%d\n\tny from %d to %d\n",
              0, 0, sim_params->nx - 1, 0, sim_params->ny - 1);
  
  struct data ez, hx, hy;
  if (init_data(&ez, "ez", sim_params->nx, sim_params->ny, sim_params->dx,
                sim_params->dy, 0.) ||
      init_data(&hx, "hx", sim_params->nx, sim_params->ny - 1, sim_params->dx,
                sim_params->dy, 0.) ||
      init_data(&hy, "hy", sim_params->nx - 1, sim_params->ny, sim_params->dx,
                sim_params->dy, 0.)) {
    printf("Error: could not allocate data\n");
    return EXIT_FAILURE;
  }
  
  // Initialize GPU data
  struct gpu_data gpu;
  if (init_gpu_data(&gpu, &ez, &hx, &hy)) {
    printf("Error: could not allocate GPU memory\n");
    free(ez.values);
    free(hx.values);
    free(hy.values);
    return EXIT_FAILURE;
  }
  
  // Configure CUDA grid and block dimensions
  dim3 blockDim(16, 16);
  dim3 gridDim_hx((sim_params->nx + blockDim.x - 1) / blockDim.x,
                  (sim_params->ny - 1 + blockDim.y - 1) / blockDim.y);
  dim3 gridDim_hy((sim_params->nx - 1 + blockDim.x - 1) / blockDim.x,
                  (sim_params->ny + blockDim.y - 1) / blockDim.y);
  dim3 gridDim_ez((sim_params->nx + blockDim.x - 1) / blockDim.x,
                  (sim_params->ny + blockDim.y - 1) / blockDim.y);
  
  // Pre-compute constants
  double chy = sim_params->dt / (sim_params->dy * phys_params->mu);
  double chx = sim_params->dt / (sim_params->dx * phys_params->mu);
  double cex = sim_params->dt / (sim_params->dx * phys_params->eps);
  double cey = sim_params->dt / (sim_params->dy * phys_params->eps);
  
  double start = GET_TIME();
  
  for (int n = 0; n < sim_params->nt; n++) {
    if (n && (n % (sim_params->nt / 10)) == 0) {
      double time_sofar = GET_TIME() - start;
      double eta = (sim_params->nt - n) * time_sofar / n;
#ifndef STABILITY_STUDY
      printf("Computing time step %d/%d (ETA: %g seconds)     \r", n,
             sim_params->nt, eta);
      fflush(stdout);
#endif
    }
    
    // Update hx on GPU
    update_hx_kernel<<<gridDim_hx, blockDim>>>(gpu.d_hx, gpu.d_ez,
                                                sim_params->nx, sim_params->ny, chy);
    
    // Update hy on GPU
    update_hy_kernel<<<gridDim_hy, blockDim>>>(gpu.d_hy, gpu.d_ez,
                                                sim_params->nx, sim_params->ny, chx);
    
    // Update ez on GPU
    update_ez_kernel<<<gridDim_ez, blockDim>>>(gpu.d_ez, gpu.d_hx, gpu.d_hy,
                                                sim_params->nx, sim_params->ny, cex, cey);
    
    // Check for kernel errors
    cudaError_t err = cudaGetLastError();
    if (err != cudaSuccess) {
      printf("CUDA kernel error at step %d: %s\n", n, cudaGetErrorString(err));
      break;
    }
    
#ifdef STABILITY_STUDY
    // Copy back one value for stability study
    int idx = (sim_params->nx >> 1) + 42;
    int idy = (sim_params->ny >> 1) + 42;
    double val;
    cudaMemcpy(&val, &gpu.d_ez[sim_params->nx * idy + idx], 
               sizeof(double), cudaMemcpyDeviceToHost);
    printf("%.12f \n", val);
#endif
    
    // Impose source
    double t = n * sim_params->dt;
    double source_val;
    int src_x = sim_params->nx / 2;
    int src_y = sim_params->ny / 2;
    int src_idx = sim_params->nx * src_y + src_x;  // Column-major indexing
    
    switch (problem_id) {
    case 1:
    case 2:
      source_val = sin(2. * M_PI * 2.4e9 * t);
      cudaMemcpy(&gpu.d_ez[src_idx], &source_val, sizeof(double), 
                 cudaMemcpyHostToDevice);
      break;
    default:
      printf("Error: unknown source\n");
      break;
    }
    
    // Output step data in VTK format
    if (sim_params->sampling_rate && !(n % sim_params->sampling_rate)) {
      // Copy data back to host for VTK output
      cudaMemcpy(ez.values, gpu.d_ez, 
                 sim_params->nx * sim_params->ny * sizeof(double),
                 cudaMemcpyDeviceToHost);
      write_data_vtk(&ez, n, 0);
    }
  }
  
  // Synchronize to ensure all kernels have completed
  cudaDeviceSynchronize();
  
  // Copy final results back to host
  cudaMemcpy(ez.values, gpu.d_ez, 
             sim_params->nx * sim_params->ny * sizeof(double),
             cudaMemcpyDeviceToHost);
  
  // Cleanup
  free_gpu_data(&gpu);
  free(ez.values);
  free(hx.values);
  free(hy.values);
  
  printf("\n");
  return EXIT_SUCCESS;
}
